# ğŸ“Š Daily Property Crawler

This project is an **automated web scraper** that:
- âœ… Reads a list of property URLs from an **Excel input file**
- âœ… Scrapes fresh daily data (pricing, availability, reviews, amenities, etc.)
- âœ… Outputs the results as a **daily Excel snapshot**
- âœ… Runs automatically every day using **GitHub Actions**
- âœ… Uploads the output file as an **artifact** you can download anytime

---

## ğŸš€ **How it works**

1ï¸âƒ£ **Input**  
- `properties.xlsx`  
  - Contains the list of relevant properties (Airbnb, Gathern, etc.)
  - You maintain this file â€” just edit, commit, and push updates.

2ï¸âƒ£ **Scraper**  
- `scrape.py` loads the input file, loops through each URL, scrapes data, and stores it in a DataFrame.
- Generates a new `YYYY-MM-DD-snapshot.xlsx` in the `output/` folder.

3ï¸âƒ£ **Output**  
- GitHub Actions saves the daily snapshot Excel file as an artifact attached to each workflow run.

4ï¸âƒ£ **Automation**  
- `.github/workflows/scraper.yml` runs the scraper **daily at 1 AM UTC** using GitHubâ€™s free runners.
- You can also trigger the scraper manually.

---

## ğŸ“‚ **Project structure**

